{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.functions import udf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.addPyFile(\"../.local/lib/python3.5/site-packages/mwcomments-0.3.3-py3.5.egg\")\n",
    "spark.sparkContext.addPyFile(\"../.local/lib/python3.5/site-packages/sortedcontainers-2.1.0-py3.5.egg\")\n",
    "spark.sparkContext.addPyFile(\"../.local/lib/python3.5/site-packages/python_dateutil-2.8.0-py3.5.egg\")\n",
    "spark.sparkContext.addPyFile(\"./spark_functions.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwcomments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_settings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.broadcastTimeout\",1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "remeber_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = pd.read_csv(os.path.join(data_dir,\"ores_rcfilters_cutoffs.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare 14 days before and after the cutoff\n",
    "# unless there's another cutoff less than 28 days away, in which case split the difference\n",
    "by_wiki = cutoffs.groupby('wiki_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs['date'] = pd.to_datetime(cutoffs.deploy_dt)\n",
    "cutoffs = cutoffs.drop(\"deploy_gap\",1)\n",
    "cutoffs = cutoffs.drop(\"deploy_dt\",1)\n",
    "cutoffs = cutoffs.drop(\"commit_dt\",1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cutoff_period(df):\n",
    "    df = df.sort_values(by=['date'])\n",
    "    next_cutoff = df.shift(1)\n",
    "    df['time_since_last_cutoff']  = df.date - df.shift(1).date\n",
    "    df['time_till_next_cutoff']  = df.shift(-1).date - df.date\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = cutoffs.groupby(\"wiki_db\").apply(set_cutoff_period)\n",
    "\n",
    "cutoffs = cutoffs.drop('wiki_db',1).reset_index()\n",
    "cutoffs = cutoffs.drop(\"level_1\",1)\n",
    "\n",
    "select =[ 'wiki_db','has_ores','has_rcfilters','has_rcfilters_watchlist','time_since_last_cutoff','time_till_next_cutoff','date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We special case wikis where some issues lead to changes and deployments that we don't want to analyze. \n",
    "# fawiki: bug leads to cutoff disabling ores for 2 days. These won't show up in any other interval, so ignore them. \n",
    "cutoffs = cutoffs.loc[~((cutoffs.wiki_db == 'fawiki') & ( (cutoffs.date == pd.to_datetime(\"2017-12-09 11:19:00\")) | (cutoffs.date == pd.to_datetime(\"2017-12-11 18:56:00\"))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etwiki, frwiki, and hewiki apparently turned on rcfilters 50 days after enabling ORES. This is OK. The periods overlap.\n",
    "\n",
    "#frwiki and ruwiki experienced a bug on the deployment of rcfilters to watchlist. So let's ignore them for those messages.   \n",
    "\n",
    "cutoffs = cutoffs.loc[~((cutoffs.wiki_db == 'frwiki') & (cutoffs.date >= pd.to_datetime(\"2017-11-09 14:35:00\")))]\n",
    "\n",
    "cutoffs = cutoffs.loc[~((cutoffs.wiki_db == 'ruwiki') & (cutoffs.date >= pd.to_datetime(\"2017-11-20 19:22:00\") ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_db</th>\n",
       "      <th>has_ores</th>\n",
       "      <th>has_rcfilters</th>\n",
       "      <th>has_rcfilters_watchlist</th>\n",
       "      <th>time_since_last_cutoff</th>\n",
       "      <th>time_till_next_cutoff</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cswiki</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>76 days 23:21:00</td>\n",
       "      <td>2017-02-22 00:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cswiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>76 days 23:21:00</td>\n",
       "      <td>308 days 17:24:00</td>\n",
       "      <td>2017-05-09 23:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>etwiki</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>50 days 05:26:00</td>\n",
       "      <td>2017-03-20 18:28:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>etwiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>50 days 05:26:00</td>\n",
       "      <td>308 days 17:24:00</td>\n",
       "      <td>2017-05-09 23:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>frwiki</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>55 days 07:02:00</td>\n",
       "      <td>2017-04-11 11:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>frwiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>55 days 07:02:00</td>\n",
       "      <td>156 days 20:24:00</td>\n",
       "      <td>2017-06-05 18:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hewiki</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>29 days 10:38:00</td>\n",
       "      <td>2017-04-10 13:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hewiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>29 days 10:38:00</td>\n",
       "      <td>308 days 17:24:00</td>\n",
       "      <td>2017-05-09 23:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kowiki</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2019-03-04 16:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>kowiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-03-04 16:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>wikidatawiki</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>169 days 13:27:00</td>\n",
       "      <td>3 days 23:58:00</td>\n",
       "      <td>2017-10-26 13:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>wikidatawiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3 days 23:58:00</td>\n",
       "      <td>28 days 05:52:00</td>\n",
       "      <td>2017-10-30 13:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>wikidatawiki</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>28 days 05:52:00</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2017-11-27 19:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>wikidatawiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-11-27 19:11:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wiki_db has_ores has_rcfilters has_rcfilters_watchlist  \\\n",
       "3         cswiki     True         False                   False   \n",
       "4         cswiki     True          True                   False   \n",
       "12        etwiki     True         False                   False   \n",
       "13        etwiki     True          True                   False   \n",
       "22        frwiki    False         False                   False   \n",
       "23        frwiki     True          True                   False   \n",
       "27        hewiki     True         False                   False   \n",
       "28        hewiki     True          True                   False   \n",
       "32        kowiki    False          True                   False   \n",
       "33        kowiki     True          True                    True   \n",
       "65  wikidatawiki    False         False                   False   \n",
       "66  wikidatawiki     True          True                    True   \n",
       "67  wikidatawiki    False         False                   False   \n",
       "68  wikidatawiki     True          True                    True   \n",
       "\n",
       "    time_since_last_cutoff  time_till_next_cutoff                date  \n",
       "3                      NaT       76 days 23:21:00 2017-02-22 00:33:00  \n",
       "4         76 days 23:21:00      308 days 17:24:00 2017-05-09 23:54:00  \n",
       "12                     NaT       50 days 05:26:00 2017-03-20 18:28:00  \n",
       "13        50 days 05:26:00      308 days 17:24:00 2017-05-09 23:54:00  \n",
       "22                     NaT       55 days 07:02:00 2017-04-11 11:09:00  \n",
       "23        55 days 07:02:00      156 days 20:24:00 2017-06-05 18:11:00  \n",
       "27                     NaT       29 days 10:38:00 2017-04-10 13:16:00  \n",
       "28        29 days 10:38:00      308 days 17:24:00 2017-05-09 23:54:00  \n",
       "32                     NaT        0 days 00:00:00 2019-03-04 16:27:00  \n",
       "33         0 days 00:00:00                    NaT 2019-03-04 16:27:00  \n",
       "65       169 days 13:27:00        3 days 23:58:00 2017-10-26 13:21:00  \n",
       "66         3 days 23:58:00       28 days 05:52:00 2017-10-30 13:19:00  \n",
       "67        28 days 05:52:00        0 days 00:00:00 2017-11-27 19:11:00  \n",
       "68         0 days 00:00:00                    NaT 2017-11-27 19:11:00  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs.loc[(cutoffs.time_since_last_cutoff<=pd.Timedelta(120,'D')) | (cutoffs.time_till_next_cutoff<=pd.Timedelta(120,'D')), select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_db</th>\n",
       "      <th>index</th>\n",
       "      <th>commitsha</th>\n",
       "      <th>damaging_hard</th>\n",
       "      <th>damaging_likelybad_max</th>\n",
       "      <th>damaging_likelybad_min</th>\n",
       "      <th>damaging_likelygood_max</th>\n",
       "      <th>damaging_likelygood_min</th>\n",
       "      <th>damaging_maybebad_max</th>\n",
       "      <th>damaging_maybebad_min</th>\n",
       "      <th>...</th>\n",
       "      <th>extension_status_default</th>\n",
       "      <th>rcfilters_watchlist_enabled_default</th>\n",
       "      <th>commitsha_default</th>\n",
       "      <th>has_extension</th>\n",
       "      <th>has_beta_extension</th>\n",
       "      <th>has_rcfilters</th>\n",
       "      <th>has_rcfilters_watchlist</th>\n",
       "      <th>date</th>\n",
       "      <th>time_since_last_cutoff</th>\n",
       "      <th>time_till_next_cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arwiki</td>\n",
       "      <td>0</td>\n",
       "      <td>c19a7d1dd4f8b720ef99cd5a33a9853a0555fa1c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>maximum recall @ precision &gt;= 0.45</td>\n",
       "      <td>maximum recall @ precision &gt;= 0.997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>22f6ec8967a3b66019881f27bb37515eaae855bc</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-05-09 18:04:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  wiki_db  index                                 commitsha  damaging_hard  \\\n",
       "0  arwiki      0  c19a7d1dd4f8b720ef99cd5a33a9853a0555fa1c            NaN   \n",
       "\n",
       "   damaging_likelybad_max              damaging_likelybad_min  \\\n",
       "0                     1.0  maximum recall @ precision >= 0.45   \n",
       "\n",
       "               damaging_likelygood_max  damaging_likelygood_min  \\\n",
       "0  maximum recall @ precision >= 0.997                      0.0   \n",
       "\n",
       "   damaging_maybebad_max damaging_maybebad_min          ...           \\\n",
       "0                    NaN                   NaN          ...            \n",
       "\n",
       "   extension_status_default  rcfilters_watchlist_enabled_default  \\\n",
       "0                       NaN                                 True   \n",
       "\n",
       "                          commitsha_default has_extension has_beta_extension  \\\n",
       "0  22f6ec8967a3b66019881f27bb37515eaae855bc         False              False   \n",
       "\n",
       "   has_rcfilters  has_rcfilters_watchlist                date  \\\n",
       "0           True                     True 2018-05-09 18:04:00   \n",
       "\n",
       "   time_since_last_cutoff time_till_next_cutoff  \n",
       "0                     NaT                   NaT  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs.loc[cutoffs.wiki_db == 'arwiki']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kowiki was enabled over two commits with the same deploy time\n",
    "cutoffs = cutoffs.drop(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_db</th>\n",
       "      <th>has_ores</th>\n",
       "      <th>has_rcfilters</th>\n",
       "      <th>has_rcfilters_watchlist</th>\n",
       "      <th>time_since_last_cutoff</th>\n",
       "      <th>time_till_next_cutoff</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>wikidatawiki</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>321 days 08:41:00</td>\n",
       "      <td>2016-06-22 15:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>wikidatawiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>321 days 08:41:00</td>\n",
       "      <td>169 days 13:27:00</td>\n",
       "      <td>2017-05-09 23:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>wikidatawiki</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>169 days 13:27:00</td>\n",
       "      <td>3 days 23:58:00</td>\n",
       "      <td>2017-10-26 13:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>wikidatawiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3 days 23:58:00</td>\n",
       "      <td>28 days 05:52:00</td>\n",
       "      <td>2017-10-30 13:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>wikidatawiki</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>28 days 05:52:00</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>2017-11-27 19:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>wikidatawiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-11-27 19:11:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wiki_db has_ores has_rcfilters has_rcfilters_watchlist  \\\n",
       "63  wikidatawiki     True         False                   False   \n",
       "64  wikidatawiki     True          True                   False   \n",
       "65  wikidatawiki    False         False                   False   \n",
       "66  wikidatawiki     True          True                    True   \n",
       "67  wikidatawiki    False         False                   False   \n",
       "68  wikidatawiki     True          True                    True   \n",
       "\n",
       "    time_since_last_cutoff  time_till_next_cutoff                date  \n",
       "63                     NaT      321 days 08:41:00 2016-06-22 15:13:00  \n",
       "64       321 days 08:41:00      169 days 13:27:00 2017-05-09 23:54:00  \n",
       "65       169 days 13:27:00        3 days 23:58:00 2017-10-26 13:21:00  \n",
       "66         3 days 23:58:00       28 days 05:52:00 2017-10-30 13:19:00  \n",
       "67        28 days 05:52:00        0 days 00:00:00 2017-11-27 19:11:00  \n",
       "68         0 days 00:00:00                    NaT 2017-11-27 19:11:00  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs.loc[cutoffs.wiki_db == 'wikidatawiki',select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikidatawiki had an issue on 2017-10-30 and 2017-11-27 with the move to default on watchlist so we'll ignore that cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = cutoffs.loc[~((cutoffs.wiki_db == 'wikidatawiki') & (cutoffs.date >= pd.to_datetime(\"2017-10-26 13:21:00\")))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_db</th>\n",
       "      <th>has_ores</th>\n",
       "      <th>has_rcfilters</th>\n",
       "      <th>has_rcfilters_watchlist</th>\n",
       "      <th>time_since_last_cutoff</th>\n",
       "      <th>time_till_next_cutoff</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>etwiki</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>50 days 05:26:00</td>\n",
       "      <td>2017-03-20 18:28:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>etwiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>50 days 05:26:00</td>\n",
       "      <td>308 days 17:24:00</td>\n",
       "      <td>2017-05-09 23:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>frwiki</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>55 days 07:02:00</td>\n",
       "      <td>2017-04-11 11:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>frwiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>55 days 07:02:00</td>\n",
       "      <td>156 days 20:24:00</td>\n",
       "      <td>2017-06-05 18:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hewiki</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>29 days 10:38:00</td>\n",
       "      <td>2017-04-10 13:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hewiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>29 days 10:38:00</td>\n",
       "      <td>308 days 17:24:00</td>\n",
       "      <td>2017-05-09 23:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>kowiki</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2019-03-04 16:27:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wiki_db has_ores has_rcfilters has_rcfilters_watchlist  \\\n",
       "12  etwiki     True         False                   False   \n",
       "13  etwiki     True          True                   False   \n",
       "22  frwiki    False         False                   False   \n",
       "23  frwiki     True          True                   False   \n",
       "27  hewiki     True         False                   False   \n",
       "28  hewiki     True          True                   False   \n",
       "33  kowiki     True          True                    True   \n",
       "\n",
       "    time_since_last_cutoff  time_till_next_cutoff                date  \n",
       "12                     NaT       50 days 05:26:00 2017-03-20 18:28:00  \n",
       "13        50 days 05:26:00      308 days 17:24:00 2017-05-09 23:54:00  \n",
       "22                     NaT       55 days 07:02:00 2017-04-11 11:09:00  \n",
       "23        55 days 07:02:00      156 days 20:24:00 2017-06-05 18:11:00  \n",
       "27                     NaT       29 days 10:38:00 2017-04-10 13:16:00  \n",
       "28        29 days 10:38:00      308 days 17:24:00 2017-05-09 23:54:00  \n",
       "33         0 days 00:00:00                    NaT 2019-03-04 16:27:00  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs.loc[(cutoffs.time_since_last_cutoff<=pd.Timedelta(60,'D')) | (cutoffs.time_till_next_cutoff<=pd.Timedelta(60,'D')), select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cutoff = cutoffs.groupby(['wiki_db']).date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll look over the range of dates starting in June 2017 after thresholds in model info were released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remember[\"min.first.cutoff\"] = first_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_first_cutoff = datetime(year=2017,month=6,day=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cutoff = first_cutoff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cutoff.loc[(first_cutoff.date < min_first_cutoff),\"date\"] = min_first_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cutoff = first_cutoff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cutoff = cutoffs.merge(first_cutoff,how='right')[['wiki_db','date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_cutoff = cutoffs.groupby(['wiki_db']).date.max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_cutoff = cutoffs.merge(last_cutoff,how='right')[['wiki_db','date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_cutoff = last_cutoff.merge(first_cutoff,on='wiki_db',suffixes=['_last','_first'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_period_length = pd.Timedelta(365,'d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remember['rdd_period_length'] = rdd_period_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_cutoff['period2_end'] = fl_cutoff.date_last + rdd_period_length\n",
    "fl_cutoff['period1_start'] = fl_cutoff.date_first - rdd_period_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmhist = spark.read.table(\"wmf.mediawiki_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a stratified sample of edits in the cutoffs\n",
    "# stratify by wiki_db, is_newcomer, is_anon, is_reverted, and pre-ores and post-ores periods\n",
    "wmhist = spark.read.table(\"wmf.mediawiki_history\")\n",
    "\n",
    "wmhist = wmhist.filter(f.col(\"snapshot\") == \"2019-10\")\n",
    "# ok we're ready to fire up spark and make a stratified sample\n",
    "# we only need the latest snapshot\n",
    "\n",
    "wmhist = wmhist.filter((f.col(\"event_entity\") == \"revision\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark_functions import build_wmhist_step1, process_reverts, broadcast_match_comment, add_revert_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function spark_functions.broadcast_match_comment.<locals>.my_match_comment>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcast_match_comment(spark.sparkContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmhist = wmhist.filter(wmhist.page_namespace == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmhist = build_wmhist_step1(wmhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wmhist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverts = process_reverts(wmhist,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the columns we need from reverts\n",
    "reverts = reverts.select(['wiki_db_l','revert_timestamp','reverted_revision_id',f.col('role_type').alias(\"revert_role_type\"),f.col('anon_new_established').alias('reverted_anon_new_established'),'is_damage','time_to_revert','revert_comment','revert_user_Nreverts_past_month','revert_user_text','revert_user_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the time to revert analysis, we only want damaging ones, but for is_reverted we want all reverts\n",
    "wmhist = wmhist.join(reverts, on =[wmhist.wiki_db == reverts.wiki_db_l, wmhist.revision_id == reverts.reverted_revision_id],how='left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wmhist = wmhist.join(cutoffs, on=[wmhist.wiki_db==cutoffs.wiki_db_l, f.unix_timestamp(wmhist.event_timestamp) >= f.unix_timestamp(cutoffs.period_start), f.unix_timestamp(wmhist.event_timestamp) <= f.unix_timestamp(cutoffs.period_end)],how='right_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wmhist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wmhist = wmhist.withColumn(\"sec_to_cutoff\", (f.unix_timestamp(f.col(\"event_timestamp\")) - f.unix_timestamp(f.col(\"date\"))) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wmhist = add_revert_types(wmhist, comment_column='revert_comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of taking a sample around every cutoff. We're going to just look 3 months before the earliest cutoff and 3 months after the latest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_cutoff_df = spark.createDataFrame(fl_cutoff[['wiki_db','date_first','date_last','period1_start','period2_end']])\n",
    "fl_cutoff_df = fl_cutoff_df.withColumnRenamed('wiki_db','wiki_db_l')\n",
    "fl_cutoff_df = f.broadcast(fl_cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[wiki_db_l: string, date_first: timestamp, date_last: timestamp, period1_start: timestamp, period2_end: timestamp]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_cutoff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_cond = (wmhist.wiki_db == fl_cutoff_df.wiki_db_l) & (f.unix_timestamp(wmhist.event_timestamp).between(f.unix_timestamp(fl_cutoff_df.period1_start),f.unix_timestamp(fl_cutoff_df.date_first)) | (f.unix_timestamp(wmhist.event_timestamp).between(f.unix_timestamp(fl_cutoff_df.date_last),f.unix_timestamp(fl_cutoff_df.period2_end))))\n",
    "\n",
    "                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wmhist = wmhist.repartition(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmhist = wmhist.join(fl_cutoff_df,on=join_cond, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ores_cutoff_cond = None\n",
    "# rcfilters_cutoff_cond = None\n",
    "# rcfilters_watchlist_cutoff_cond = None\n",
    "# for _, cutoff in cutoffs.iterrows():\n",
    "#     cond = ((wmhist.wiki_db == cutoff.wiki_db) & (f.unix_timestamp(wmhist.event_timestamp) >= cutoff.period_start.timestamp()) & (f.unix_timestamp(wmhist.event_timestamp) <= cutoff.period_end.timestamp()))\n",
    "            \n",
    "#     if ores_cutoff_cond is None:\n",
    "#         ores_cutoff_cond = (cond & f.lit(cutoff.ores_cutoff == True))\n",
    "#         rcfilters_cutoff_cond = (cond & f.lit(cutoff.rcfilters_cutoff == True))\n",
    "#         rcfilters_watchlist_cutoff_cond = (cond & f.lit(cutoff.watchlist_cutoff == True))\n",
    "#     else:\n",
    "#         ores_cutoff_cond = ores_cutoff_cond | (cond & f.lit(cutoff.ores_cutoff == True))\n",
    "#         rcfilters_cutoff_cond = rcfilters_cutoff_cond | (cond & f.lit(cutoff.rcfilters_cutoff == True))\n",
    "#         rcfilters_watchlist_cutoff_cond = rcfilters_watchlist_cutoff_cond | (cond & f.lit(cutoff.watchlist_cutoff == True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wmhist = wmhist.withColumn(\"cutoff_type\", f.when(ores_cutoff_cond,'has_ores').otherwise(f.when(rcfilters_cutoff_cond,'has_rcfilters').otherwise(f.when(rcfilters_watchlist_cutoff_cond,'has_rcfilters_watchlist').otherwise(None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmhist = wmhist.withColumn(\"period\",f.when(f.unix_timestamp(wmhist.event_timestamp) <= f.unix_timestamp(wmhist.date_first),\"period1\").otherwise(\"period2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmhist = wmhist.withColumn('strata',f.concat_ws('_',wmhist.wiki_db,wmhist.period,wmhist.revision_is_identity_reverted,wmhist.reverted_anon_new_established))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmhist = wmhist.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wmhist.select(f.col(\"anon_new_established\"),f.col(\"reverted_anon_new_established\"),f.col(\"revision_id\"),f.col(\"revert_role_type\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmhist = wmhist.withColumn(\"reverted_in_24h\",(wmhist.revision_is_identity_reverted == True) & (wmhist.time_to_revert <= 60*60*24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wmhist = wmhist.repartition(1200,f.col(\"strata\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wiki_db',\n",
       " 'event_entity',\n",
       " 'event_type',\n",
       " 'event_timestamp',\n",
       " 'event_comment',\n",
       " 'event_user_id',\n",
       " 'event_user_text_historical',\n",
       " 'event_user_text',\n",
       " 'event_user_blocks_historical',\n",
       " 'event_user_blocks',\n",
       " 'event_user_groups_historical',\n",
       " 'event_user_groups',\n",
       " 'event_user_is_bot_by_historical',\n",
       " 'event_user_is_bot_by',\n",
       " 'event_user_is_created_by_self',\n",
       " 'event_user_is_created_by_system',\n",
       " 'event_user_is_created_by_peer',\n",
       " 'event_user_is_anonymous',\n",
       " 'event_user_registration_timestamp',\n",
       " 'event_user_creation_timestamp',\n",
       " 'event_user_first_edit_timestamp',\n",
       " 'event_user_revision_count',\n",
       " 'event_user_seconds_since_previous_revision',\n",
       " 'page_id',\n",
       " 'page_title_historical',\n",
       " 'page_title',\n",
       " 'page_namespace_historical',\n",
       " 'page_namespace_is_content_historical',\n",
       " 'page_namespace',\n",
       " 'page_namespace_is_content',\n",
       " 'page_is_redirect',\n",
       " 'page_is_deleted',\n",
       " 'page_creation_timestamp',\n",
       " 'page_first_edit_timestamp',\n",
       " 'page_revision_count',\n",
       " 'page_seconds_since_previous_revision',\n",
       " 'user_id',\n",
       " 'user_text_historical',\n",
       " 'user_text',\n",
       " 'user_blocks_historical',\n",
       " 'user_blocks',\n",
       " 'user_groups_historical',\n",
       " 'user_groups',\n",
       " 'user_is_bot_by_historical',\n",
       " 'user_is_bot_by',\n",
       " 'user_is_created_by_self',\n",
       " 'user_is_created_by_system',\n",
       " 'user_is_created_by_peer',\n",
       " 'user_is_anonymous',\n",
       " 'user_registration_timestamp',\n",
       " 'user_creation_timestamp',\n",
       " 'user_first_edit_timestamp',\n",
       " 'revision_id',\n",
       " 'revision_parent_id',\n",
       " 'revision_minor_edit',\n",
       " 'revision_deleted_parts',\n",
       " 'revision_deleted_parts_are_suppressed',\n",
       " 'revision_text_bytes',\n",
       " 'revision_text_bytes_diff',\n",
       " 'revision_text_sha1',\n",
       " 'revision_content_model',\n",
       " 'revision_content_format',\n",
       " 'revision_is_deleted_by_page_deletion',\n",
       " 'revision_deleted_by_page_deletion_timestamp',\n",
       " 'revision_is_identity_reverted',\n",
       " 'revision_first_identity_reverting_revision_id',\n",
       " 'revision_seconds_to_identity_revert',\n",
       " 'revision_is_identity_revert',\n",
       " 'revision_is_from_before_page_creation',\n",
       " 'revision_tags',\n",
       " 'snapshot',\n",
       " 'event_user_is_newcomer',\n",
       " 'anon_new_established',\n",
       " 'event_user_isadmin',\n",
       " 'event_user_isbot1',\n",
       " 'event_user_ispatroller',\n",
       " 'event_user_isbot2',\n",
       " 'role_type',\n",
       " 'wiki_db_l',\n",
       " 'revert_timestamp',\n",
       " 'reverted_revision_id',\n",
       " 'revert_role_type',\n",
       " 'reverted_anon_new_established',\n",
       " 'is_damage',\n",
       " 'time_to_revert',\n",
       " 'revert_comment',\n",
       " 'revert_user_Nreverts_past_month',\n",
       " 'revert_user_text',\n",
       " 'revert_user_id',\n",
       " 'wiki_db_l',\n",
       " 'date_first',\n",
       " 'date_last',\n",
       " 'period1_start',\n",
       " 'period2_end',\n",
       " 'period',\n",
       " 'strata',\n",
       " 'reverted_in_24h']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmhist.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmhist_out = wmhist.select(['wiki_db','event_timestamp','page_id','page_title','user_id','user_text','event_user_isbot1','event_user_isbot2','revision_id','revision_is_identity_reverted','anon_new_established','event_user_is_newcomer','time_to_revert','reverted_in_24h','period','period1_start','period2_end','strata','date_first','date_last'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmhist_out = wmhist_out.repartition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o2148.csv.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:198)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:664)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Could not execute broadcast in 300 secs. You can increase the timeout for broadcasts via spark.sql.broadcastTimeout or disable broadcast join by setting spark.sql.autoBroadcastJoinThreshold to -1\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:150)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:387)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:144)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:140)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:140)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:117)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenInner(BroadcastHashJoinExec.scala:211)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:101)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:189)\n\tat org.apache.spark.sql.execution.InputAdapter.consume(WholeStageCodegenExec.scala:374)\n\tat org.apache.spark.sql.execution.InputAdapter.doProduce(WholeStageCodegenExec.scala:403)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.InputAdapter.produce(WholeStageCodegenExec.scala:374)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:96)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:544)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:598)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder.buildBuffers(InMemoryRelation.scala:83)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder.cachedColumnBuffers(InMemoryRelation.scala:59)\n\tat org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.filteredCachedBatches(InMemoryTableScanExec.scala:276)\n\tat org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD$lzycompute(InMemoryTableScanExec.scala:105)\n\tat org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD(InMemoryTableScanExec.scala:104)\n\tat org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.doExecute(InMemoryTableScanExec.scala:310)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:143)\n\t... 33 more\nCaused by: java.util.concurrent.TimeoutException: Futures timed out after [300 seconds]\n\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)\n\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:146)\n\t... 110 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-306-98459bf4fa98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwmhist_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/user/nathante/ores_bias_data/cutoff_revisions_2periods.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'overwrite'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"None\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark2/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue)\u001b[0m\n\u001b[1;32m    929\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                        encoding=encoding, emptyValue=emptyValue)\n\u001b[0;32m--> 931\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark2/python/lib/py4j-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark2/python/lib/py4j-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2148.csv.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:198)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:664)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Could not execute broadcast in 300 secs. You can increase the timeout for broadcasts via spark.sql.broadcastTimeout or disable broadcast join by setting spark.sql.autoBroadcastJoinThreshold to -1\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:150)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:387)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:144)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:140)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:140)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:117)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenInner(BroadcastHashJoinExec.scala:211)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:101)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:189)\n\tat org.apache.spark.sql.execution.InputAdapter.consume(WholeStageCodegenExec.scala:374)\n\tat org.apache.spark.sql.execution.InputAdapter.doProduce(WholeStageCodegenExec.scala:403)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.InputAdapter.produce(WholeStageCodegenExec.scala:374)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:96)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:544)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:598)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder.buildBuffers(InMemoryRelation.scala:83)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder.cachedColumnBuffers(InMemoryRelation.scala:59)\n\tat org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.filteredCachedBatches(InMemoryTableScanExec.scala:276)\n\tat org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD$lzycompute(InMemoryTableScanExec.scala:105)\n\tat org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD(InMemoryTableScanExec.scala:104)\n\tat org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.doExecute(InMemoryTableScanExec.scala:310)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:143)\n\t... 33 more\nCaused by: java.util.concurrent.TimeoutException: Futures timed out after [300 seconds]\n\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)\n\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:146)\n\t... 110 more\n"
     ]
    }
   ],
   "source": [
    "wmhist_out.write.csv(\"/user/nathante/ores_bias_data/cutoff_revisions_2periods.csv\",mode='overwrite',compression=\"None\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proportion of observations in each strata\n",
    "strata_count = wmhist.groupby(f.col('strata')).count()\n",
    "#all_count = wmhist.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strata_count = strata_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(strata='testwiki_period1_true_newcomer', count=15),\n",
       " Row(strata='test2wiki_period1_true_established', count=10),\n",
       " Row(strata='sqwiki_period2_true_newcomer', count=92),\n",
       " Row(strata='fawiki_period1_true_established', count=9519),\n",
       " Row(strata='frwiki_period2_false', count=1619122),\n",
       " Row(strata='fawiki_period1_false', count=358573),\n",
       " Row(strata='euwiki_period1_true_anonymous', count=522),\n",
       " Row(strata='wikidatawiki_period1_false', count=34402609),\n",
       " Row(strata='euwiki_period1_true_established', count=143),\n",
       " Row(strata='plwiki_period2_true_anonymous', count=17380),\n",
       " Row(strata='ruwiki_period1_true_anonymous', count=66800),\n",
       " Row(strata='ptwiki_period1_true_newcomer', count=5824),\n",
       " Row(strata='svwiki_period1_true_newcomer', count=1529),\n",
       " Row(strata='rowiki_period1_true_established', count=853),\n",
       " Row(strata='hewiki_period1_true', count=6629),\n",
       " Row(strata='hewiki_period2_true', count=9744),\n",
       " Row(strata='kowiki_period1_true_anonymous', count=16113),\n",
       " Row(strata='ruwiki_period2_true', count=18868),\n",
       " Row(strata='enwiki_period2_false', count=9055941),\n",
       " Row(strata='hewiki_period1_true_established', count=21389),\n",
       " Row(strata='cawiki_period2_true_anonymous', count=4304),\n",
       " Row(strata='fiwiki_period1_true_anonymous', count=6972),\n",
       " Row(strata='rowiki_period2_true_newcomer', count=474),\n",
       " Row(strata='hewiki_period1_true_newcomer', count=1453),\n",
       " Row(strata='sqwiki_period1_true_established', count=115),\n",
       " Row(strata='simplewiki_period1_false', count=51179),\n",
       " Row(strata='sqwiki_period1_false', count=11710),\n",
       " Row(strata='eswikiquote_period1_true_anonymous', count=337),\n",
       " Row(strata='srwiki_period2_true', count=2076),\n",
       " Row(strata='fawiki_period2_true_established', count=17873),\n",
       " Row(strata='fiwiki_period1_false', count=151590),\n",
       " Row(strata='plwiki_period1_true_established', count=7564),\n",
       " Row(strata='ruwiki_period2_true_newcomer', count=4094),\n",
       " Row(strata='trwiki_period2_true_anonymous', count=2106),\n",
       " Row(strata='hewiki_period2_true_newcomer', count=1506),\n",
       " Row(strata='nlwiki_period1_true_established', count=12839),\n",
       " Row(strata='testwiki_period2_true_newcomer', count=18),\n",
       " Row(strata='itwiki_period2_true', count=21880),\n",
       " Row(strata='huwiki_period2_true_newcomer', count=671),\n",
       " Row(strata='ptwiki_period2_true', count=11241),\n",
       " Row(strata='srwiki_period1_false', count=789043),\n",
       " Row(strata='lvwiki_period1_true_anonymous', count=1970),\n",
       " Row(strata='lvwiki_period2_true_established', count=123),\n",
       " Row(strata='cawiki_period2_true', count=1392),\n",
       " Row(strata='enwiki_period2_true', count=229947),\n",
       " Row(strata='eswikiquote_period2_true_newcomer', count=26),\n",
       " Row(strata='cawiki_period1_true', count=1849),\n",
       " Row(strata='trwiki_period1_true_anonymous', count=18293),\n",
       " Row(strata='etwiki_period1_true', count=460),\n",
       " Row(strata='huwiki_period1_true_anonymous', count=7081),\n",
       " Row(strata='srwiki_period2_true_established', count=2076),\n",
       " Row(strata='ptwiki_period2_true_anonymous', count=50027),\n",
       " Row(strata='bswiki_period2_true_newcomer', count=68),\n",
       " Row(strata='svwiki_period2_true', count=2501),\n",
       " Row(strata='rowiki_period1_true_anonymous', count=2446),\n",
       " Row(strata='enwiki_period1_true_established', count=340777),\n",
       " Row(strata='testwiki_period2_false', count=514),\n",
       " Row(strata='frwiki_period2_true_newcomer', count=4863),\n",
       " Row(strata='kowiki_period1_true_newcomer', count=1060),\n",
       " Row(strata='svwiki_period1_true', count=2683),\n",
       " Row(strata='simplewiki_period2_true_established', count=867),\n",
       " Row(strata='plwiki_period2_true', count=4802),\n",
       " Row(strata='cswiki_period2_true_established', count=2137),\n",
       " Row(strata='eswiki_period1_false', count=1330449),\n",
       " Row(strata='srwiki_period1_true_newcomer', count=375),\n",
       " Row(strata='mediawikiwiki_period2_true_newcomer', count=80),\n",
       " Row(strata='kowiki_period2_true_newcomer', count=780),\n",
       " Row(strata='cswiki_period1_false', count=288970),\n",
       " Row(strata='simplewiki_period2_true_anonymous', count=10190),\n",
       " Row(strata='kowiki_period1_false', count=376436),\n",
       " Row(strata='hewiki_period2_true_anonymous', count=20804),\n",
       " Row(strata='etwiki_period2_true_newcomer', count=114),\n",
       " Row(strata='ptwiki_period1_true_established', count=15101),\n",
       " Row(strata='testwiki_period1_false', count=898),\n",
       " Row(strata='fawiki_period1_true', count=6213),\n",
       " Row(strata='fiwiki_period2_true_newcomer', count=903),\n",
       " Row(strata='test2wiki_period1_true', count=20),\n",
       " Row(strata='bswiki_period1_true', count=75),\n",
       " Row(strata='nlwiki_period2_true_established', count=8397),\n",
       " Row(strata='fiwiki_period2_true_anonymous', count=6534),\n",
       " Row(strata='mediawikiwiki_period2_true_established', count=112),\n",
       " Row(strata='trwiki_period1_true_newcomer', count=3447),\n",
       " Row(strata='nlwiki_period1_true_anonymous', count=31871),\n",
       " Row(strata='testwiki_period2_true_established', count=61),\n",
       " Row(strata='hewiki_period2_true_established', count=15751),\n",
       " Row(strata='simplewiki_period1_true', count=3106),\n",
       " Row(strata='lvwiki_period1_false', count=36643),\n",
       " Row(strata='kowiki_period2_false', count=377840),\n",
       " Row(strata='euwiki_period1_true', count=469),\n",
       " Row(strata='svwiki_period2_true_newcomer', count=1510),\n",
       " Row(strata='enwiki_period1_false', count=8694648),\n",
       " Row(strata='cswiki_period1_true', count=2602),\n",
       " Row(strata='rowiki_period2_false', count=79765),\n",
       " Row(strata='fiwiki_period2_true_established', count=1893),\n",
       " Row(strata='svwiki_period1_true_anonymous', count=10917),\n",
       " Row(strata='cawiki_period2_true_newcomer', count=369),\n",
       " Row(strata='ptwiki_period2_false', count=538825),\n",
       " Row(strata='huwiki_period2_true_anonymous', count=6188),\n",
       " Row(strata='rowiki_period2_true_established', count=1387),\n",
       " Row(strata='bswiki_period1_true_established', count=122),\n",
       " Row(strata='bswiki_period2_true_established', count=82),\n",
       " Row(strata='arwiki_period2_true_established', count=17864),\n",
       " Row(strata='itwiki_period2_true_established', count=23806),\n",
       " Row(strata='itwiki_period1_true_established', count=22454),\n",
       " Row(strata='sqwiki_period1_true', count=222),\n",
       " Row(strata='etwiki_period2_false', count=64603),\n",
       " Row(strata='trwiki_period1_false', count=292996),\n",
       " Row(strata='test2wiki_period2_true_established', count=2),\n",
       " Row(strata='srwiki_period2_true_newcomer', count=347),\n",
       " Row(strata='trwiki_period2_true', count=1219),\n",
       " Row(strata='eswikiquote_period1_true_newcomer', count=10),\n",
       " Row(strata='eswiki_period2_true_newcomer', count=16245),\n",
       " Row(strata='fawiki_period1_true_newcomer', count=3387),\n",
       " Row(strata='eswikiquote_period1_false', count=4743),\n",
       " Row(strata='nlwiki_period2_false', count=341393),\n",
       " Row(strata='simplewiki_period2_false', count=67132),\n",
       " Row(strata='test2wiki_period2_true_newcomer', count=2),\n",
       " Row(strata='enwiki_period2_true_anonymous', count=654655),\n",
       " Row(strata='plwiki_period1_true_anonymous', count=14711),\n",
       " Row(strata='huwiki_period1_true_newcomer', count=598),\n",
       " Row(strata='sqwiki_period2_true_established', count=311),\n",
       " Row(strata='fiwiki_period1_true_newcomer', count=993),\n",
       " Row(strata='plwiki_period1_false', count=564387),\n",
       " Row(strata='eswiki_period2_true_established', count=31285),\n",
       " Row(strata='eswikibooks_period2_true_established', count=5),\n",
       " Row(strata='itwiki_period1_true_newcomer', count=4480),\n",
       " Row(strata='eswikibooks_period2_true_anonymous', count=582),\n",
       " Row(strata='itwiki_period2_true_anonymous', count=76255),\n",
       " Row(strata='eswiki_period1_true_newcomer', count=15150),\n",
       " Row(strata='wikidatawiki_period2_true_established', count=176564),\n",
       " Row(strata='etwiki_period1_true_anonymous', count=1125),\n",
       " Row(strata='kowiki_period1_true_established', count=4869),\n",
       " Row(strata='frwiki_period1_true_anonymous', count=88058),\n",
       " Row(strata='rowiki_period1_true', count=2598),\n",
       " Row(strata='trwiki_period2_false', count=120403),\n",
       " Row(strata='wikidatawiki_period2_true', count=104788),\n",
       " Row(strata='bswiki_period1_false', count=13802),\n",
       " Row(strata='itwiki_period2_true_newcomer', count=4232),\n",
       " Row(strata='euwiki_period2_true', count=347),\n",
       " Row(strata='eswiki_period1_true_established', count=31208),\n",
       " Row(strata='simplewiki_period1_true_established', count=1358),\n",
       " Row(strata='lvwiki_period1_true', count=345),\n",
       " Row(strata='wikidatawiki_period1_true_newcomer', count=1890),\n",
       " Row(strata='rowiki_period1_false', count=122675),\n",
       " Row(strata='enwiki_period2_true_newcomer', count=92865),\n",
       " Row(strata='nlwiki_period2_true', count=7051),\n",
       " Row(strata='eswikiquote_period2_true', count=62),\n",
       " Row(strata='arwiki_period2_false', count=524434),\n",
       " Row(strata='nlwiki_period1_true', count=8694),\n",
       " Row(strata='testwiki_period2_true_anonymous', count=11),\n",
       " Row(strata='kowiki_period1_true', count=10536),\n",
       " Row(strata='eswiki_period1_true_anonymous', count=179205),\n",
       " Row(strata='svwiki_period2_true_anonymous', count=10463),\n",
       " Row(strata='ptwiki_period2_true_newcomer', count=4004),\n",
       " Row(strata='simplewiki_period2_true_newcomer', count=961),\n",
       " Row(strata='mediawikiwiki_period1_true_anonymous', count=528),\n",
       " Row(strata='svwiki_period1_true_established', count=2293),\n",
       " Row(strata='eswikibooks_period2_true_newcomer', count=18),\n",
       " Row(strata='mediawikiwiki_period2_true_anonymous', count=471),\n",
       " Row(strata='cswiki_period1_true_newcomer', count=499),\n",
       " Row(strata='huwiki_period1_true_established', count=1791),\n",
       " Row(strata='cswiki_period2_false', count=156352),\n",
       " Row(strata='nlwiki_period1_false', count=386327),\n",
       " Row(strata='frwiki_period2_true', count=17321),\n",
       " Row(strata='wikidatawiki_period2_true_anonymous', count=19388),\n",
       " Row(strata='fiwiki_period2_true', count=1412),\n",
       " Row(strata='rowiki_period2_true', count=1367),\n",
       " Row(strata='lvwiki_period2_false', count=50567),\n",
       " Row(strata='itwiki_period1_true_anonymous', count=75746),\n",
       " Row(strata='ptwiki_period1_true', count=16322),\n",
       " Row(strata='bswiki_period2_true', count=191),\n",
       " Row(strata='plwiki_period1_true', count=4612),\n",
       " Row(strata='kowiki_period2_true_anonymous', count=15825),\n",
       " Row(strata='fawiki_period2_true_newcomer', count=3345),\n",
       " Row(strata='eswiki_period2_true_anonymous', count=217495),\n",
       " Row(strata='huwiki_period1_false', count=221978),\n",
       " Row(strata='frwiki_period1_true_newcomer', count=8342),\n",
       " Row(strata='frwiki_period2_true_established', count=24696),\n",
       " Row(strata='bswiki_period1_true_newcomer', count=59),\n",
       " Row(strata='enwiki_period1_true_anonymous', count=623450),\n",
       " Row(strata='huwiki_period1_true', count=1984),\n",
       " Row(strata='kowiki_period2_true', count=12556),\n",
       " Row(strata='ruwiki_period2_true_anonymous', count=58352),\n",
       " Row(strata='etwiki_period1_false', count=49870),\n",
       " Row(strata='itwiki_period1_false', count=1109565),\n",
       " Row(strata='svwiki_period1_false', count=262772),\n",
       " Row(strata='srwiki_period2_false', count=271380),\n",
       " Row(strata='fiwiki_period1_true', count=1725),\n",
       " Row(strata='huwiki_period2_false', count=250784),\n",
       " Row(strata='mediawikiwiki_period1_false', count=18509),\n",
       " Row(strata='ruwiki_period1_true', count=20453),\n",
       " Row(strata='cswiki_period2_true', count=2157),\n",
       " Row(strata='cswiki_period2_true_anonymous', count=7413),\n",
       " Row(strata='enwiki_period1_true_newcomer', count=77939),\n",
       " Row(strata='euwiki_period2_true_anonymous', count=438),\n",
       " Row(strata='test2wiki_period2_true', count=12),\n",
       " Row(strata='ptwiki_period1_true_anonymous', count=80870),\n",
       " Row(strata='eswiki_period1_true', count=39583),\n",
       " Row(strata='arwiki_period1_true_newcomer', count=4651),\n",
       " Row(strata='arwiki_period2_true', count=12033),\n",
       " Row(strata='eswikiquote_period2_true_established', count=32),\n",
       " Row(strata='testwiki_period1_true_established', count=39),\n",
       " Row(strata='eswikiquote_period2_false', count=6932),\n",
       " Row(strata='nlwiki_period2_true_anonymous', count=26508),\n",
       " Row(strata='wikidatawiki_period1_true_established', count=108861),\n",
       " Row(strata='lvwiki_period2_true', count=384),\n",
       " Row(strata='bswiki_period1_true_anonymous', count=471),\n",
       " Row(strata='trwiki_period2_true_newcomer', count=394),\n",
       " Row(strata='sqwiki_period1_true_newcomer', count=59),\n",
       " Row(strata='trwiki_period1_true_established', count=8307),\n",
       " Row(strata='svwiki_period2_true_established', count=1977),\n",
       " Row(strata='test2wiki_period2_false', count=81),\n",
       " Row(strata='wikidatawiki_period1_true', count=57297),\n",
       " Row(strata='cawiki_period2_true_established', count=758),\n",
       " Row(strata='arwiki_period1_false', count=640843),\n",
       " Row(strata='test2wiki_period1_true_newcomer', count=3),\n",
       " Row(strata='ptwiki_period1_false', count=511203),\n",
       " Row(strata='test2wiki_period1_false', count=278),\n",
       " Row(strata='lvwiki_period2_true_anonymous', count=629),\n",
       " Row(strata='ruwiki_period2_false', count=1151020),\n",
       " Row(strata='fawiki_period2_false', count=406493),\n",
       " Row(strata='plwiki_period2_true_established', count=6436),\n",
       " Row(strata='rowiki_period2_true_anonymous', count=3998),\n",
       " Row(strata='testwiki_period1_true_anonymous', count=15),\n",
       " Row(strata='eswikibooks_period1_true_established', count=3),\n",
       " Row(strata='nlwiki_period2_true_newcomer', count=1655),\n",
       " Row(strata='mediawikiwiki_period1_true_newcomer', count=118),\n",
       " Row(strata='testwiki_period2_true', count=107),\n",
       " Row(strata='lvwiki_period1_true_established', count=99),\n",
       " Row(strata='eswikibooks_period1_true_anonymous', count=410),\n",
       " Row(strata='itwiki_period2_false', count=1486651),\n",
       " Row(strata='arwiki_period1_true_established', count=34291),\n",
       " Row(strata='eswikibooks_period2_true', count=57),\n",
       " Row(strata='simplewiki_period2_true', count=2954),\n",
       " Row(strata='fawiki_period1_true_anonymous', count=13428),\n",
       " Row(strata='nlwiki_period1_true_newcomer', count=1800),\n",
       " Row(strata='trwiki_period2_true_established', count=1660),\n",
       " Row(strata='etwiki_period1_true_established', count=274),\n",
       " Row(strata='eswikibooks_period1_true_newcomer', count=8),\n",
       " Row(strata='cawiki_period1_false', count=195401),\n",
       " Row(strata='hewiki_period1_true_anonymous', count=15649),\n",
       " Row(strata='testwiki_period1_true', count=74),\n",
       " Row(strata='sqwiki_period2_true_anonymous', count=1078),\n",
       " Row(strata='sqwiki_period1_true_anonymous', count=749),\n",
       " Row(strata='sqwiki_period2_false', count=14479),\n",
       " Row(strata='eswiki_period2_true', count=43123),\n",
       " Row(strata='euwiki_period2_true_newcomer', count=27),\n",
       " Row(strata='hewiki_period1_false', count=372299),\n",
       " Row(strata='hewiki_period2_false', count=391735),\n",
       " Row(strata='wikidatawiki_period2_true_newcomer', count=1825),\n",
       " Row(strata='frwiki_period1_true_established', count=25902),\n",
       " Row(strata='eswikibooks_period2_false', count=3736),\n",
       " Row(strata='arwiki_period2_true_anonymous', count=21728),\n",
       " Row(strata='bswiki_period2_false', count=8687),\n",
       " Row(strata='eswikiquote_period2_true_anonymous', count=296),\n",
       " Row(strata='wikidatawiki_period1_true_anonymous', count=16800),\n",
       " Row(strata='eswikiquote_period1_true_established', count=18),\n",
       " Row(strata='frwiki_period1_true', count=22840),\n",
       " Row(strata='cawiki_period1_true_established', count=927),\n",
       " Row(strata='euwiki_period2_false', count=47836),\n",
       " Row(strata='mediawikiwiki_period2_false', count=13142),\n",
       " Row(strata='trwiki_period1_true', count=4822),\n",
       " Row(strata='mediawikiwiki_period1_true', count=245),\n",
       " Row(strata='bswiki_period2_true_anonymous', count=338),\n",
       " Row(strata='cswiki_period2_true_newcomer', count=619),\n",
       " Row(strata='plwiki_period1_true_newcomer', count=914),\n",
       " Row(strata='srwiki_period1_true', count=2485),\n",
       " Row(strata='enwiki_period1_true', count=236846),\n",
       " Row(strata='plwiki_period2_true_newcomer', count=1153),\n",
       " Row(strata='arwiki_period1_true_anonymous', count=26377),\n",
       " Row(strata='mediawikiwiki_period2_true', count=209),\n",
       " Row(strata='itwiki_period1_true', count=21010),\n",
       " Row(strata='simplewiki_period1_true_newcomer', count=750),\n",
       " Row(strata='srwiki_period1_true_anonymous', count=4215),\n",
       " Row(strata='ruwiki_period1_true_newcomer', count=4057),\n",
       " Row(strata='huwiki_period2_true', count=2338),\n",
       " Row(strata='cswiki_period1_true_anonymous', count=6404),\n",
       " Row(strata='srwiki_period2_true_anonymous', count=3918),\n",
       " Row(strata='cawiki_period1_true_anonymous', count=7827),\n",
       " Row(strata='sqwiki_period2_true', count=496),\n",
       " Row(strata='arwiki_period2_true_newcomer', count=5117),\n",
       " Row(strata='rowiki_period1_true_newcomer', count=336),\n",
       " Row(strata='ptwiki_period2_true_established', count=10835),\n",
       " Row(strata='eswikiquote_period1_true', count=59),\n",
       " Row(strata='mediawikiwiki_period1_true_established', count=230),\n",
       " Row(strata='ruwiki_period2_true_established', count=23481),\n",
       " Row(strata='enwiki_period2_true_established', count=302776),\n",
       " Row(strata='etwiki_period2_true_established', count=450),\n",
       " Row(strata='cawiki_period1_true_newcomer', count=651),\n",
       " Row(strata='cawiki_period2_false', count=198045),\n",
       " Row(strata='kowiki_period2_true_established', count=4693),\n",
       " Row(strata='wikidatawiki_period2_false', count=49249965),\n",
       " Row(strata='ruwiki_period1_true_established', count=25257),\n",
       " Row(strata='plwiki_period2_false', count=538334),\n",
       " Row(strata='euwiki_period1_false', count=84568),\n",
       " Row(strata='svwiki_period2_false', count=334349),\n",
       " Row(strata='fawiki_period2_true', count=7092),\n",
       " Row(strata='cswiki_period1_true_established', count=3575),\n",
       " Row(strata='lvwiki_period1_true_newcomer', count=77),\n",
       " Row(strata='test2wiki_period1_true_anonymous', count=11),\n",
       " Row(strata='etwiki_period2_true_anonymous', count=1429),\n",
       " Row(strata='fiwiki_period2_false', count=146517),\n",
       " Row(strata='eswikibooks_period1_true', count=63),\n",
       " Row(strata='eswiki_period2_false', count=1449886),\n",
       " Row(strata='etwiki_period2_true', count=725),\n",
       " Row(strata='arwiki_period1_true', count=9654),\n",
       " Row(strata='eswikibooks_period1_false', count=3409),\n",
       " Row(strata='lvwiki_period2_true_newcomer', count=29),\n",
       " Row(strata='fiwiki_period1_true_established', count=1486),\n",
       " Row(strata='frwiki_period2_true_anonymous', count=51947),\n",
       " Row(strata='euwiki_period2_true_established', count=66),\n",
       " Row(strata='etwiki_period1_true_newcomer', count=114),\n",
       " Row(strata='frwiki_period1_false', count=1810095),\n",
       " Row(strata='huwiki_period2_true_established', count=1959),\n",
       " Row(strata='euwiki_period1_true_newcomer', count=47),\n",
       " Row(strata='ruwiki_period1_false', count=1236217),\n",
       " Row(strata='fawiki_period2_true_anonymous', count=16527),\n",
       " Row(strata='srwiki_period1_true_established', count=1446),\n",
       " Row(strata='simplewiki_period1_true_anonymous', count=10174)]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strata_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strata_count = strata_count.withColumn(\"fraction\", f.when( 20000 < f.col(\"count\"),20000/f.col(\"count\")).otherwise(1))\n",
    "strata_count = strata_count.withColumn(\"weight\",1/strata_count.fraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remember['strata_sample_size'] = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_design = strata_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fractions = samp_design.locj['strata','fraction']\n",
    "fractions = {r.strata:r.fraction for r in samp_design}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = wmhist.sampleBy(\"strata\",fractions=fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.join(strata_count,on='strata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.select(['wiki_db','event_timestamp','page_id','page_title','user_id','user_text','event_user_isbot1','event_user_isbot2','revision_id','revision_is_identity_reverted','reverted_in_24h','time_to_revert','anon_new_established','event_user_is_newcomer','revert_tool','period_start','period_end','date','pre_cutoff','fraction','weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Write the table. check if it exists and get the sample revids from there.\n",
    "\n",
    "sample.write.saveAsTable(\"nathante.cutoff_revisions_sample_simplestrata\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.repartition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.write.csv(\"/user/nathante/ores_bias_data/cutoff_revisions_sample_simplestrata.csv\",mode='overwrite',compression='None',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "strata_count.write.csv(\"/user/nathante/ores_bias_data/threshhold_strata_counts.csv\",mode='overwrite',compression=\"None\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|avg(CAST(revision_is_identity_reverted AS BIGINT))|\n",
      "+--------------------------------------------------+\n",
      "|                                0.5336424575374225|\n",
      "+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample.filter(sample.wiki_db=='enwiki').select(f.mean(f.col('revision_is_identity_reverted').cast(\"long\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = spark.sparkContext.getConf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edits2 = edits.select(['wiki_db','event_timestamp','event_user_is_anonymous','event_user_is_anonymous','revision_id','revision_is_identity_reverted','rcfilters_cutoff','week','sec_to_cutoff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edits2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ores_scores = spark.read.table(\"ores.revision_score_public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ores_scores = ores_scores.filter((f.col(\"model\")==\"damaging\") & f.col(\"model_version\") == \"0.3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edits = edits.join(ores_scores,on=[edits.wiki_db == ores_scores.wiki, edits.revision_id == ores_scores.rev_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edits2 = edits2.withColumn(\"wikiweek\",f.concat_ws(' ', edits.wiki_db, f.date_format(edits.week,'MM-dd-yyyy')))\n",
    "by_wiki_week = edits.groupby('wikiweek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_wiki_week = edits2.groupby(['wikiweek'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample stratified of N = 5000 by wiki and week\n",
    "\n",
    "samp_design = by_wiki_week.count()\n",
    "samp_design = samp_design.withColumn(\"fraction\", f.when( 5000 < f.col(\"count\"),5000/f.col(\"count\")).otherwise(1))\n",
    "samp_design = samp_design.withColumn(\"weight\",1/samp_design.fraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = samp_design.select(['wikiweek','fraction']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = {r.wikiweek:r.fraction for r in fractions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = edits2.sampleBy(\"wikiweek\",fractions=fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pddf_sample = sample.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark - YARN - 12g",
   "language": "python",
   "name": "spark_yarn_pyspak_nathante_12g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
